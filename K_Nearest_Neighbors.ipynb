{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN is one of the simplest classifier supervised machine learning algorithm. Instead of training a model, KNN will predict the class of an observation by using the K features close to the observation using some metrics such as Euclidean, Manhattan, or Minkowski. Then the K features vote based on their classs and a class with majority of votes wins.   \n",
    "\n",
    "It should be noted that the features should be standardized in order to get the best result.\n",
    "\n",
    "We use Iris flower data set or Fisher's Iris data set for our practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest neighbors are:  [[[1.03800476 0.55861082 1.10378283 1.18556721]\n",
      "  [0.79566902 0.32841405 0.76275827 1.05393502]]]\n",
      "Distances are:  [[0.49140089 0.74294782]]\n"
     ]
    }
   ],
   "source": [
    "# Nearst Neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "X_standard = standardizer.fit_transform(X)\n",
    "\n",
    "#neares_neighbor = NearestNeighbors(n_neighbors=2).fit(X_standard)\n",
    "\n",
    "# metric shows the metric used to compute the distance between observation: Euclidean, Manhattan, Minkowski\n",
    "neares_neighbor = NearestNeighbors(n_neighbors=2, metric='euclidean').fit(X_standard)\n",
    "\n",
    "observation = [1, 1, 1, 1]\n",
    "distances, indices = neares_neighbor.kneighbors([observation]) \n",
    "\n",
    "print(\"The closest neighbors are: \", X_standard[indices])\n",
    "print(\"Distances are: \", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Nearst Neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "X_std = standardizer.fit_transform(X)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1).fit(X_std, y)\n",
    "\n",
    "observation = [[0.75, 0.75, 0.75, 0.75],[1, 1, 1, 1]]\n",
    "\n",
    "knn.predict(observation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best K\n",
    "\n",
    "Chossing the optimal value for the hyperparameter K, is an important issue in applying KNN algorithm. If k=1, the the algorithm has high variance. If k=n (number of observations), the the algorithm will have high bias. We have to choose the best value for K such that the algorithm has low variance and low bias. The best value of K can be chosen by using GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is k = 6\n"
     ]
    }
   ],
   "source": [
    "# Best K\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "X_std = standardizer.fit_transform(X)\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "pipe = Pipeline([(\"standardizer\", standardizer), (\"knn\", knn)])\n",
    "\n",
    "search_space = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "classifier = GridSearchCV(pipe, search_space, cv=5, verbose=0).fit(X_std, y)\n",
    "\n",
    "print(\"The best value is\", \"k =\",classifier.best_estimator_.get_params()[\"knn__n_neighbors\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radius-Based Neighbor Classifier\n",
    "\n",
    "In radius-based neighbor classifier, instead of using K nearest neighbor, we predict the class of an observation within a given radiu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Radius Nearst Neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "X_std = standardizer.fit_transform(X)\n",
    "\n",
    "rnn = RadiusNeighborsClassifier(radius=.5, n_jobs=-1).fit(X_std, y)\n",
    "\n",
    "observation = [[1, 1, 1, 1]]\n",
    "\n",
    "rnn.predict(observation)\n",
    "\n",
    "#print(\"The closest neighbors are: \", X_standard[indices])\n",
    "#print(\"Distances are: \", distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
